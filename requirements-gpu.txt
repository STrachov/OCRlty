# -------------------- HF / vLLM stack --------------------
transformers==4.57.1
tokenizers==0.22.1
huggingface_hub>=0.23,<1.0
sentencepiece>=0.1.99
tiktoken>=0.6
cachetools>=5,<6
einops>=0.7

# -------------------- API / runtime --------------------
fastapi>=0.120,<1.0
uvicorn[standard]>=0.38
httpx>=0.28
python-multipart>=0.0.9
pydantic>=2.5
loguru>=0.7
numpy>=1.25,<3
pandas>=2.3,<3
msgspec>=0.18,<0.20

# -------------------- OCR / PDF --------------------
paddlepaddle-gpu==2.6.1
paddleocr>=3.3,<4.0
opencv-contrib-python-headless==4.10.0.84
pypdfium2>=5.0.0
pdfminer.six==20250506
shapely>=2.0
pyclipper>=1.3
rapidfuzz>=3.14
python-bidi==0.6.7

# ---- vLLM runtime deps (wheel installed with --no-deps) ----
cloudpickle>=2.2
cachetools>=5.3
diskcache>=5.6
einops>=0.7
pynvml>=11.5
packaging>=24
filelock>=3.12
pyyaml>=6
tqdm>=4.66
pyzmq>=25,<26
blake3>=0.3,<1
openai>=1,<2
aiohttp>=3.9,<4
aiosignal>=1.3,<2
async-timeout>=4,<5
frozenlist>=1.4,<2
multidict>=6,<7
yarl>=1.9,<2

# quality-of-life (обычно используются логгер/сериализация)
rich>=13,<14
orjson>=3.10,<4
