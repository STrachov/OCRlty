# OCRlty ‚Äî –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø–ª–∞–Ω (CPU-OCR + GPU-TILT –≤ –æ–¥–Ω–æ–º –ø–æ–¥–µ RunPod)
**TL;DR**: –ù–∞ –ø—Ä–æ–¥–µ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–¥–∏–Ω –ø–æ–¥ –Ω–∞ RunPod, –≥–¥–µ –≤ –æ–¥–Ω–æ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ –∫—Ä—É—Ç—è—Ç—Å—è **FastAPI + (vLLM + Arctic-TILT) (GPU)** –∏ **FastAPI + PaddleOCR 3.x (CPU)**. OCR –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–∞ CPU —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–æ–º; TILT –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —á–µ—Ä–µ–∑ –æ–±–µ—Ä—Ç–∫—É FastAPI. –î–ª—è –ª–æ–∫–∞–ª–∫–∏ ‚Äî Docker Desktop + WSL2, –º–æ–∫ vLLM.
---
## 1) –¶–µ–ª–∏ –∏ –≥—Ä–∞–Ω–∏—Ü—ã (–±–µ–∑ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–π —á–∞—Å—Ç–∏)
- **–¶–µ–ª—å**: —Å–µ—Ä–≤–∏—Å Dev-API, –ø—Ä–∏–Ω–∏–º–∞—é—â–∏–π PDF/JPG/PNG —Å—á–µ—Ç–æ–≤/–∏–Ω–≤–æ–π—Å–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—â–∏–π –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π JSON (merchant, date, currency, subtotal, tax_amount, total).
- **–ì—Ä–∞–Ω–∏—Ü—ã**: —Ç–æ–ª—å–∫–æ API –∏ pipeline (OCR ‚Üí KIE). –ö–ª–∏–µ–Ω—Ç—Å–∫–æ–π UI-—á–∞—Å—Ç–∏ –Ω–µ—Ç.
- **–ú–æ–¥–µ–ª–∏**:
  - OCR: **PaddleOCR 3.x** (CPU), `paddlepaddle==3.1.0`.
  - KIE: **Snowflake/snowflake-arctic-tilt-v1.3** —á–µ—Ä–µ–∑ **vLLM 0.8.3** (GPU).
---
## 2) –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–ø—Ä–æ–¥)
**–û–¥–∏–Ω –ø–æ–¥ RunPod** (–æ–¥–∏–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, –¥–≤–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞):
[Container]
‚îú‚îÄ vLLM + Arctic-TILT (GPU) :8001
‚îî‚îÄ FastAPI + PaddleOCR (CPU) :8000

–ü–æ—Ç–æ–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞:
1) API —á–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–Ω–¥–µ—Ä–∏—Ç PDF ‚Üí PNG (pypdfium2).
2) **PaddleOCR.predict** (CPU) ‚Üí –¥–µ—Ç–µ–∫—Ç –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫ (–ø–∞—Ä–∞–ª–ª–µ–ª–∏–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ).
3) –§–æ—Ä–º–∏—Ä—É–µ–º **OCR Document** (`pages[].{width,height,spans[{bbox,text}]}`).
4) –®–ª—ë–º –≤ vLLM `/v1/tilt/generate` —Å –∑–∞–ø—Ä–æ—Å–æ–º —Ç–∏–ø–∞:
curl -X POST "http://127.0.0.1:8001/v1/tilt/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is the total amount on this document? Answer only the number.",
    "temperature": 0.0,
    "max_tokens": 8,
    "pages": [
      {
        "ocr": {
          "width": 1000,
          "height": 1400,
          "words": [
            { "text": "Total",    "bbox": [100, 200, 220, 230] },
            { "text": "56",       "bbox": [230, 200, 340, 230] },
            ...
            { "text": "VAT",      "bbox": [100, 260, 170, 290] },
            { "text": "20%",      "bbox": [180, 260, 230, 290] }
          ]
        }
      }
    ]
  }'

5) –ü–∞—Ä—Å–∏–º JSON, –ø—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–∞–≤–∏–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏, –æ—Ç–¥–∞—ë–º –æ—Ç–≤–µ—Ç.

---

## 3) –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
‚îú‚îÄ apps/
‚îÇ ‚îú‚îÄ api_gpu/ # FastAPI + inference 
‚îÇ ‚îî‚îÄ tilt_api.py/ # FastAPI + vLLM + Arctic-TILT
‚îú‚îÄ configs/ # yaml/json –∫–æ–Ω—Ñ–∏–≥–∏ –º–æ–¥–µ–ª–µ–π/–ø—Ä–∞–≤–∏–ª/–ª–æ–∫–∞–ª–µ–π
‚îú‚îÄ docs/ # OpenAPI-export, –ø—Ä–∏–º–µ—Ä—ã, –¥–∏–∞–≥—Ä–∞–º–º—ã, SLA
‚îú‚îÄ lib/
‚îÇ ‚îú‚îÄ pipelines/
‚îÇ ‚îÇ ‚îú‚îÄ tilt_client.py # –∫–ª–∏–µ–Ω—Ç –∫ vLLM (OpenAI chat)
‚îÇ ‚îÇ ‚îú‚îÄ tilt_prep.py # OCR‚ÜíOCR Document‚Üímessages
‚îÇ ‚îÇ ‚îî‚îÄ extract.py # –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è —Å—Ç–∞–¥–∏–π (OCR‚ÜíKIE)
‚îÇ ‚îî‚îÄ post/rules.py # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è/–≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–¥–∞—Ç—ã/–≤–∞–ª—é—Ç—ã/—Å—É–º–º)
‚îú‚îÄ notebooks/
‚îÇ ‚îî‚îÄ gpu/ # R&D
‚îú‚îÄ tests/ # –ø–æ–∫–∞ –≤—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø–æ—Ç–æ–º unit + integ + e2e)
‚îú‚îÄ scripts/ # build, warmup, eval, bootstrap 
‚îÇ  ‚îú‚îÄ mock_vllm.py         # (CPU) –ª–æ–∫–∞–ª—å–Ω—ã–π mock OpenAI API
‚îÇ  ‚îî‚îÄ bootstrap_*.sh       # —É—Ç–∏–ª–∏—Ç—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏/–ø—Ä–æ–≤–µ—Ä–∫–∏
‚îú‚îÄ pyproject.toml
‚îú‚îÄ requirements-cpu.txt
‚îú‚îÄ requirements-gpu.txt
‚îú‚îÄ docker-compose.dev.yml
‚îú‚îÄ Dockerfile.dev
‚îú‚îÄ Dockerfile
‚îú‚îÄ entrypoint.py
‚îî‚îÄ README.md
> –í–∞–∂–Ω–æ: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è **`apps/api_gpu/`** (–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ, –Ω–µ –¥–µ—Ñ–∏—Å) –∏ —Ñ–∞–π–ª—ã `__init__.py` –≤ `apps/` –∏ `apps/api_gpu/` –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞.

---

## 4) –í–µ—Ä—Å–∏–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
### 4.1 CPU-—Å—Ç–µ–∫ (API + OCR) ‚Üí `requirements-cpu.txt`
- **PaddleOCR 3.x**: `paddleocr>=3.2,<4.0`
- **PaddlePaddle (CPU)**: `paddlepaddle==3.1.0`
- (–æ–ø—Ü.) **ONNX Runtime**: `onnxruntime==1.18.1` (—É—Å–∫–æ—Ä–µ–Ω–∏–µ —á–µ—Ä–µ–∑ HPI)
- PDF/–≤—Ö–æ–¥—ã: `pypdfium2>=4.20`, `pdfminer.six>=20221105`
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/–≥–µ–æ–º–µ—Ç—Ä–∏—è: `opencv-python-headless>=4.9,<5.0, `Pillow>=10.2``, `shapely>=2.0`, `pyclipper>=1.3`, `rapidfuzz>=3.0`
- API: `fastapi>=0.110, `python-multipart>=0.0.9``, `uvicorn[standard]>=0.27`, `pydantic>=2.5`, `httpx>=0.27`, `loguru>=0.7`
- –ë–∞–∑–æ–≤—ã–µ: `numpy>=1.25,<3`

### 4.2 GPU-—Å—Ç–µ–∫ (vLLM + TILT) ‚Üí `requirements-gpu.txt`
- **vLLM**: `vllm==0.8.3`
- HF-—ç–∫–æ—Å–∏—Å—Ç–µ–º–∞: `huggingface_hub>=0.23`, `tokenizers>=0.15,<0.20`, `tiktoken>=0.6`, `sentencepiece>=0.1.99`
- (–æ–ø—Ü.) Torch –ø–æ–¥ CUDA –æ–±—Ä–∞–∑ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å–±–æ—Ä–∫–æ–π).

> –í dev-–æ–±—Ä–∞–∑–∞—Ö –¥–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ª–∏–±—ã –¥–ª—è OpenCV: `libgl1 libglib2.0-0 libsm6 libxext6 libxrender1`.
---
## 5) –õ–æ–∫–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ (Docker Desktop + WSL2)
### 5.1 Dev-compose

#### –ü—Ä–∏–º–µ—Ä `docker-compose.dev.yml`

```yaml
services:
  mock-vllm:
    build:
      context: .
      dockerfile: Dockerfile.dev
    command: uvicorn scripts.mock_vllm:app --host 0.0.0.0 --port 8001
    ports:
      - "8001:8001"
    volumes:
      - .:/app
    environment:
      - PYTHONUNBUFFERED=1

  api:
    build:
      context: .
      dockerfile: Dockerfile.dev
    command: uvicorn apps.api_gpu.main:app --host 0.0.0.0 --port 8000 --workers 1
    depends_on:
      - mock-vllm
    environment:
      - VLLM_BASE_URL=http://mock-vllm:8001/v1
      - MOCK_VLLM=1
      - PYTHONUNBUFFERED=1
    ports:
      - "8000:8000"
    volumes:
      - .:/app

```

–î–≤–∞ —Å–µ—Ä–≤–∏—Å–∞: **`mock-vllm`** (–º–æ–∫ OpenAI API) –∏ **`api`** (FastAPI+OCR).
- `api` –ø–æ–¥–Ω–∏–º–∞–µ—Ç—Å—è –Ω–∞ `:8000`, `--reload`, `PYTHONPATH=/app`.
- –ò—Å–∫–ª—é—á–∞–µ–º –∏–∑ reloader –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (`--reload-exclude /app/wheelhouse-gpu/*`).

–ö–æ–º–∞–Ω–¥—ã:
```bash
docker compose -f docker-compose.dev.yml up -d --build
docker compose -f docker-compose.dev.yml logs -f api
docker compose -f docker-compose.dev.yml logs -f mock-vllm
–¢–µ—Å—Ç—ã:

# Windows PowerShell
curl.exe http://localhost:8000/v1/health
curl.exe -F "file=@tests/test_ocr.png" http://localhost:8000/v1/extract

5.2 PaddleOCR smoke-—Ç–µ—Å—Ç
tests/test_paddle.py (3.x, CPU, –≤—ã–∑–æ–≤ predict()), –∑–∞–ø—É—Å–∫:
docker compose -f docker-compose.dev.yml exec api python tests/test_paddle.py tests/test_ocr.png en

6) –ü—Ä–æ–¥ (RunPod): –¥–≤–∞ —Ä–µ–∂–∏–º–∞

### 6.1 Immutable-–æ–±—Ä–∞–∑ (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ –ø–æ—Å–ª–µ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏)
**–û–¥–∏–Ω –ø–æ–¥, –¥–≤–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞** (–æ–¥–∏–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä): vLLM+TILT (GPU, :8001) –∏ FastAPI+PaddleOCR (CPU, :8000).

**ENV (–∫–ª—é—á–µ–≤—ã–µ)**
# API
API_PORT=8000
MAX_UPLOAD_MB=20
ALLOWED_CONTENT_TYPES=application/pdf,image/jpeg,image/png
OCR_LANG=en
OCR_DEVICE=cpu
OCR_CONCURRENCY=3
OMP_NUM_THREADS=1
VLLM_BASE_URL=http://127.0.0.1:8001/v1
VLLM_API_KEY=secret-or-dummy
RULES_ENABLED=1

# vLLM
TILT_MODEL=Snowflake/snowflake-arctic-tilt-v1.3
VLLM_PORT=8001
VLLM_GPU_UTIL=0.85

**entrypoint (—É–ø—Ä–æ—â—ë–Ω–Ω–æ)**
scripts/entrypoint.sh –∑–∞–ø—É—Å–∫–∞–µ—Ç vLLM, –∂–¥—ë—Ç /v1/models, –∑–∞—Ç–µ–º –ø–æ–¥–Ω–∏–º–∞–µ—Ç Uvicorn:
```bash
python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --port "$VLLM_PORT"   --model "$TILT_MODEL" --dtype auto --gpu-memory-utilization "$VLLM_GPU_UTIL" &
# wait-for vLLM ...
uvicorn apps.api_gpu.main:app --host 0.0.0.0 --port "$API_PORT" --workers 1
```

**–¢—é–Ω–∏–Ω–≥**
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –∫ vLLM (–æ–¥–∏–Ω httpx.AsyncClient –Ω–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, keep-alive).
- OCR –≤ –ø—É–ª–µ –ø–æ—Ç–æ–∫–æ–≤: anyio.to_thread.run_sync(ocr.predict, path) + asyncio.Semaphore(OCR_CONCURRENCY).
- OMP_NUM_THREADS=1‚Äì2.
- –•–µ–ª—Å—á–µ–∫–∏: /v1/health (API), /v1/models (vLLM).

---

### 6.2 Git‚Äëmode (–±–µ–∑ DockerHub): local ‚Üî GitHub ‚Üî RunPod + Network Volume
**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** –ø–µ—Ä–≤—ã–µ –∏—Ç–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–¥-—Ä–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏—è, –±—ã—Å—Ç—Ä—ã–µ —Ö–æ—Ç—Ñ–∏–∫—Å—ã –ø—Ä—è–º–æ —Å Pod (pull/push), –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π cold‚Äëstart.

**–°–µ—Ç–∞–ø Pod**
- **Base Image**: `ghcr.io/vllm-project/vllm-openai:latest` (Python+CUDA+vLLM).
- **Network Volume ‚Üí `/workspace/nv`**, –≥–¥–µ —Ö—Ä–∞–Ω–∏–º:
  - `/workspace/nv/src` ‚Äî –∫–æ–¥ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (**.git**);
  - `/workspace/nv/venv` ‚Äî –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ Python;
  - `/workspace/nv/wheelhouse` ‚Äî –∫—ç—à—å **wheels** –¥–ª—è –æ—Ñ—Ñ–ª–∞–π–Ω —É—Å—Ç–∞–Ω–æ–≤–∫–∏;
  - `/workspace/nv/cache/hf` ‚Äî –∫—ç—à–∏ –º–æ–¥–µ–ª–µ–π HF;
  - `/workspace/nv/logs` ‚Äî –ª–æ–≥–∏;
  - `/workspace/nv/.ssh` ‚Äî SSH‚Äë–∫–ª—é—á (–¥–ª—è GitHub deploy key/machine user).
- **–ü–æ—Ä—Ç—ã**: 8000 (API), 8001 (vLLM).

**ENV (–º–∏–Ω–∏–º—É–º)**
```
GIT_REPO=git@github.com/<owner>/<repo>.git
GIT_BRANCH=main
API_DIR=apps/api_gpu
REQS_FILE=requirements-prod.txt
MODEL_NAME=Snowflake/snowflake-arctic-tilt-v1.3

HF_HOME=/workspace/nv/cache/hf
VLLM_GPU_UTIL=0.85
PORT_API=8000
PORT_VLLM=8001
OMP_NUM_THREADS=1

# Git/SSH
USE_SSH=1
SSH_KEY_PATH=/workspace/nv/.ssh/id_ed25519
GIT_USER_NAME="RunPod Bot"
GIT_USER_EMAIL="runpod@example.local"
# (–¥–ª—è HTTPS –≤–º–µ—Å—Ç–æ SSH) USE_SSH=0 –∏ GH_TOKEN=<PAT>
```

**–°—Ç–∞—Ä—Ç–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞ (RunPod ‚Üí Container ‚Üí Command)**
```bash
bash -lc "chmod +x /workspace/nv/src/scripts/runpod_bootstrap_git.sh || true;   if [ ! -f /workspace/nv/src/scripts/runpod_bootstrap_git.sh ]; then     mkdir -p /workspace/nv/src/scripts &&     curl -fsSL 'https://raw.githubusercontent.com/<YOU>/<REPO>/<BRANCH>/scripts/runpod_bootstrap_git.sh' -o /workspace/nv/src/scripts/runpod_bootstrap_git.sh;     chmod +x /workspace/nv/src/scripts/runpod_bootstrap_git.sh;   fi;   /workspace/nv/src/scripts/runpod_bootstrap_git.sh"
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç bootstrap**
1) –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç git/ssh –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç **SSH** –∏–ª–∏ **HTTPS+PAT**.
2) `git clone` (–∏–ª–∏ fast‚Äëupdate) ‚Üí `/workspace/nv/src` (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –º–µ–∂–¥—É —Ä–µ—Å—Ç–∞—Ä—Ç–∞–º–∏).
3) –ü–æ `REQS_FILE` —Å–æ–∑–¥–∞—ë—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç **venv** –≤ `/workspace/nv/venv`.
   - –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ—Ç—Å—è **–æ—Ñ—Ñ–ª–∞–π–Ω** –∏–∑ `/workspace/nv/wheelhouse`, –µ—Å–ª–∏ –∫–æ–ª—ë—Å –Ω–µ—Ç ‚Äî —Å—Ç–∞–≤–∏—Ç –∏–∑ PyPI –∏ **–∫—ç—à–∏—Ä—É–µ—Ç –∫–æ–ª—ë—Å–∞** –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç–∞—Ä—Ç–æ–≤.
4) –°—Ç–∞—Ä—Ç—É–µ—Ç vLLM (–ø–æ—Ä—Ç `PORT_VLLM`), –∂–¥—ë—Ç `/v1/models`, –ø–æ–¥–Ω–∏–º–∞–µ—Ç FastAPI (–ø–æ—Ä—Ç `PORT_API`).

**–ü—É—à–∏ —Å Pod**
```bash
cd /workspace/nv/src
git switch -c hotfix/runpod-$(date +%Y%m%d-%H%M)
# ... –ø—Ä–∞–≤–∫–∏ ...
git add -A && git commit -m "Hotfix from RunPod"
git push -u origin HEAD
# –æ—Ç–∫—Ä—ã–≤–∞–µ–º PR –≤ GitHub
```

**–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**
- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è **SSH‚Äë–∫–ª—é—á** (deploy key write –∏–ª–∏ machine user) –≤ `/workspace/nv/.ssh`.
- –ù–µ –∑–∞–ø–µ–∫–∞–µ–º —Å–µ–∫—Ä–µ—Ç—ã –≤ –æ–±—Ä–∞–∑; –∏—Å–ø–æ–ª—å–∑—É–µ–º Env/Volume.
- `git config --global --add safe.directory /workspace/nv/src` ‚Äî —á—Ç–æ–±—ã Git –Ω–µ —Ä—É–≥–∞–ª—Å—è –ø–æ–¥ root.

**–ü–æ—á–µ–º—É –±—ã—Å—Ç—Ä–æ**
- **wheelhouse + venv** –Ω–∞ Volume ‚Üí –∑–∞–≤–∏—Å–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —Å—Ç–∞–≤—è—Ç—Å—è –æ—Ñ—Ñ–ª–∞–π–Ω.
- **HF –∫–µ—à–∏** —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è ‚Üí TILT –≥–æ—Ç–æ–≤ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ–≤–∞.
- –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–∞ Volume ‚Üí –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Å–µ—Ç–µ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏ —Ä–µ—Å—Ç–∞—Ä—Ç–µ.

---

7) API –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã
7.1 GET /v1/health
–°—Ç–∞—Ç—É—Å, –≤–µ—Ä—Å–∏—è, –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å vLLM.

7.2 POST /v1/extract (single file)
Form-data file: PDF/JPG/PNG (–ª–∏–º–∏—Ç—ã –ø–æ —Ç–∏–ø—É –∏ —Ä–∞–∑–º–µ—Ä—É).
–†–µ–∑—É–ª—å—Ç–∞—Ç:
{
  "data": { "merchant": "...", "date": "YYYY-MM-DD", "currency": "ISO", "subtotal": 0.0, "tax_amount": 0.0, "total": 0.0 },
  "meta": { "request_id": "...", "model_version": "...", "ruleset_version": "..." }
}
7.3 POST /v1/extract-batch (–Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–¥–Ω–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã—Ö)
Form-data files: —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤.
–í–Ω—É—Ç—Ä–∏: OCR –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º), –∑–∞—Ç–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã–∑–æ–≤—ã vLLM.
–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —Ñ–∞–π–ª–∞–º.

8) –ü–∞–π–ø–ª–∞–π–Ω OCR ‚Üí TILT (–º–∏–Ω–∏–º—É–º –∫–æ–¥–∞)
PaddleOCR.predict(path) ‚Üí –±–µ—Ä—ë–º rec_texts –∏ rec_polys.
–°—Ç—Ä–æ–∏–º OCR Document (AABB –∏–∑ –ø–æ–ª–∏–≥–æ–Ω–æ–≤; —à–∏—Ä–∏–Ω–∞/–≤—ã—Å–æ—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã).
messages = [{"role":"user","content":[{"type":"input_ocr_document","document": ...}]}] (+ system-prompt —Å —Ç—Ä–µ–±—É–µ–º–æ–π —Å—Ö–µ–º–æ–π JSON).

POST /v1/chat/completions –Ω–∞ vLLM, –¥–æ—Å—Ç–∞—ë–º choices[0].message.content.

json.loads + postprocess_rules() (–≤–∞–ª–∏–¥–∞—Ç–æ—Ä—ã –¥–∞—Ç/–≤–∞–ª—é—Ç/—Å—É–º–º).

9) –ù–∞–±–ª—é–¥–∞–µ–º–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ
–õ–æ–≥–∏ —Å request_id, latency –ø–æ —Å—Ç–∞–¥–∏—è–º (OCR, vLLM, total).
–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –æ—à–∏–±–∫–∞–º (400/413/415/502/503/500).
–≠—Ç–∞–ª–æ–Ω–Ω—ã–µ samples/ –∏ e2e-—Ç–µ—Å—Ç—ã (PNG/PDF, –∫–∏—Ä–∏–ª–ª–∏—Ü–∞/–ª–∞—Ç–∏–Ω–∏—Ü–∞, –≤–∞–ª—é—Ç—ã).
SLA/TTR: —Ä–µ—Ç—Ä–∞–∏ vLLM –Ω–∞ 502/503; circuit-breaker –ø—Ä–∏ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏.

10) –î–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞ (–∫–æ—Ä–æ—Ç–∫–æ)
‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è —Å–≤—è–∑–∫–∞: mock-vLLM + API (Docker Desktop).
‚úÖ PaddleOCR 3.x (CPU) –∏ —Ç–µ—Å—Ç—ã.
üîú /v1/extract-batch, –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç vLLM, —Å–µ–º–∞—Ñ–æ—Ä OCR.
üîú Prod-–æ–±—Ä–∞–∑ (entrypoint.sh) –¥–ª—è RunPod (–æ–¥–∏–Ω –ø–æ–¥).
üîú –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è docs/ (OpenAPI, –ø—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤/–æ—Ç–≤–µ—Ç–æ–≤, SLA).
‚è≠Ô∏è HPI/ONNX Runtime –¥–ª—è OCR (—É—Å–∫–æ—Ä–µ–Ω–∏–µ CPU, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ).
‚è≠Ô∏è –û—á–µ—Ä–µ–¥–∏ –∑–∞–¥–∞—á (Redis/RQ) –ø—Ä–∏ —Ä–æ—Å—Ç–µ –æ–±—ä—ë–º–æ–≤ –∏ SLA –ø–æ –ø—Ä–æ–≥—Ä–µ—Å—Å—É.

11) –ó–∞–º–µ—Ç–∫–∏ –ø–æ Windows/PowerShell
–ò—Å–ø–æ–ª—å–∑—É–π curl.exe –≤–º–µ—Å—Ç–æ curl -F (PS –∞–ª–∏–∞—Å –Ω–∞ Invoke-WebRequest).
–ï—Å–ª–∏ uvicorn reloader –ø–∞–¥–∞–µ—Ç –Ω–∞ bind-mount –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –¥–æ–±–∞–≤—å --reload-exclude –∏/–∏–ª–∏ --reload-dir.
–î–ª—è OpenCV headless –Ω—É–∂–Ω—ã —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ª–∏–±—ã (–≤ –æ–±—Ä–∞–∑–µ dev): libgl1 libglib2.0-0 libsm6 libxext6 libxrender1.

12) –ü—Ä–∏–º–µ—Ä —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è TILT
‚ÄúExtract merchant, date (YYYY-MM-DD), currency (ISO 4217), subtotal, tax_amount, total from the OCR document. Return strict valid JSON with exactly these keys and numeric values as floats. If a value is missing, set it to null.‚Äù


## 6) –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (`configs/default.yaml`)
–ë–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ TILT –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.

```yaml
tilt:
  base_url: ${VLLM_BASE_URL}
  model: Snowflake/snowflake-arctic-tilt-v1.3
  timeout_s: 10.0

normalizer:
  enabled: false
```


## 7) .gitattributes (CRLF ‚Üí LF –¥–ª—è —Å–∫—Ä–∏–ø—Ç–æ–≤)
–ß—Ç–æ–±—ã shell-—Å–∫—Ä–∏–ø—Ç—ã –Ω–µ –ª–æ–º–∞–ª–∏—Å—å –∏–∑-–∑–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å—Ç—Ä–æ–∫ –≤ Windows, –¥–æ–±–∞–≤—å —Ñ–∞–π–ª `.gitattributes` –≤ –∫–æ—Ä–µ–Ω—å:

```gitattributes
*.sh text eol=lf
```

> –ò –Ω–µ –∑–∞–±—É–¥—å —Å–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–ø—Ç –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º –≤ git:  
> `git update-index --chmod=+x scripts/entrypoint.sh`


## 8) `scripts/entrypoint.sh` (–æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ vLLM + API)

```bash
#!/usr/bin/env bash
set -euo pipefail

# –ö—ç—à–∏ –∏ –ª–æ–≥–∏
export HF_HOME="${HF_HOME:-/workspace/nv/cache/hf}"
mkdir -p "$HF_HOME" /workspace/nv/logs

# –ó–∞–ø—É—Å–∫ vLLM (Arctic‚ÄëTILT) –Ω–∞ GPU
python -m vllm.entrypoints.openai.api_server   --model "Snowflake/snowflake-arctic-tilt-v1.3"   --host 0.0.0.0 --port 8001   --dtype bfloat16   --max-model-len 4096   --gpu-memory-utilization "${VLLM_GPU_UTIL:-0.80}"   > /workspace/nv/logs/vllm.log 2>&1 &

# –ñ–¥—ë–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ vLLM
for i in {1..60}; do
  if curl -fsS "http://127.0.0.1:8001/v1/models" >/dev/null; then
    break
  fi
  sleep 2
done

# –ü—Ä–æ–∫–∏–¥—ã–≤–∞–µ–º URL vLLM –¥–ª—è API (–µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω —Å–Ω–∞—Ä—É–∂–∏)
export VLLM_BASE_URL="${VLLM_BASE_URL:-http://127.0.0.1:8001/v1}"

# –ó–∞–ø—É—Å–∫ FastAPI (OCR –Ω–∞ CPU)
export OMP_NUM_THREADS="${OMP_NUM_THREADS:-1}"
exec uvicorn apps.api_gpu.main:app --host 0.0.0.0 --port 8000 --workers 1
```


## 9) –ß–µ–∫-–ª–∏—Å—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏

- [ ] `docker compose -f docker-compose.dev.yml up --build` –ø–æ–¥–Ω–∏–º–∞–µ—Ç **mock-vllm** –∏ **api** –Ω–∞ Windows (WSL2).
- [ ] `GET /v1/health` –∏ `POST /v1/extract` —Ä–∞–±–æ—Ç–∞—é—Ç –ª–æ–∫–∞–ª—å–Ω–æ.
- [ ] –ù–∞ RunPod GPU-–æ–±—Ä–∞–∑ —Å—Ç–∞—Ä—Ç—É–µ—Ç `scripts/entrypoint.sh`, vLLM –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ `/v1/models`, API ‚Äî –Ω–∞ `/v1/health`.
- [ ] –í–µ—Ä—Å–∏–∏/–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è CPU –∏ GPU –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã –ø–æ–¥ Python 3.11.
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (OpenAPI/Postman) –ª–µ–∂–∏—Ç –≤ `docs/`.


## –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ A ‚Äî Windows 10 + WSL2 + Docker Desktop (–±—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç)

1) **–í–∫–ª—é—á–∏ WSL2** (–ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ—Å–ª–µ —à–∞–≥–æ–≤ –Ω–∏–∂–µ –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è).
   ```powershell
   dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart
   dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
   wsl --set-default-version 2
   ```
2) **–£—Å—Ç–∞–Ω–æ–≤–∏ Ubuntu 22.04** –∏–∑ Microsoft Store. –ü—Ä–æ–≤–µ—Ä–∫–∞:
   ```powershell
   wsl -l -v
   ```
   –£–±–µ–¥–∏—Å—å, —á—Ç–æ –¥–∏—Å—Ç—Ä–∏–±—É—Ç–∏–≤ –≤ —Ä–µ–∂–∏–º–µ **VERSION 2**.
3) **–ü–æ—Å—Ç–∞–≤—å Docker Desktop** –∏ –≤–∫–ª—é—á–∏:
   - *Settings ‚Üí General*: Use the WSL 2 based engine.
   - *Settings ‚Üí Resources ‚Üí WSL Integration*: –≤–∫–ª—é—á–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –¥–ª—è —Ç–≤–æ–µ–≥–æ Ubuntu.
   - (–æ–ø—Ü.) *Settings ‚Üí Resources ‚Üí File Sharing*: —Ä–∞—Å—à–∞—Ä—å –ø—Ä–æ–µ–∫—Ç–Ω—ã–π –¥–∏—Å–∫ (C:).
