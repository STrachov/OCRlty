{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50fa7aac",
   "metadata": {},
   "source": [
    "\n",
    "# Week‑1 Samples Assembler (DocILE, CORD‑v2, SROIE)\n",
    "\n",
    "Этот ноутбук собирает **небольшую выборку образцов** (samples) для R&D на Неделю 1 из **локально доступных** датасетов:\n",
    "- **DocILE** (инвойсы/заказы)\n",
    "- **CORD‑v2** (розничные чеки)\n",
    "- **SROIE** (чеки)\n",
    "\n",
    "> ⚠️ **Важно:** ноутбук **ничего не скачивает**. Он предполагает, что у вас уже есть локальные копии датасетов. \n",
    "> Проверьте условия лицензирования каждого набора и используйте только допустимым способом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d63d1",
   "metadata": {},
   "source": [
    "\n",
    "## Что делает ноутбук\n",
    "1. Находит входные файлы (PDF/JPG/PNG) и ищет **аннотации** (JSON/TXT) поблизости по эвристикам.\n",
    "2. Сэмплирует фиксированное число документов для каждого датасета.\n",
    "3. Копирует выбранные примеры в структуру `samples/…` и создаёт **единый манифест** `samples/_manifests/manifest.csv`.\n",
    "4. (Опционально) Вы можете адаптировать функции обнаружения аннотаций под вашу структуру.\n",
    "\n",
    "## Структура результата\n",
    "```\n",
    "samples/\n",
    "  invoices/docile/           # выбранные примеры DocILE (инвойсы)\n",
    "    <files> + labels/\n",
    "  receipts/cord/             # выбранные примеры CORD-v2 (чеки)\n",
    "    <files> + labels/\n",
    "  receipts/sroie/            # выбранные примеры SROIE (чеки)\n",
    "    <files> + labels/\n",
    "  _manifests/manifest.csv    # единый манифест\n",
    "README.samples.md\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dbdd27",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Конфигурация\n",
    "\n",
    "Укажите пути к локальным копиям датасетов и желаемое количество документов. \n",
    "Вы также можете передать параметры через переменные окружения (например, в Docker/RunPod).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# === УКАЖИТЕ СВОИ ПУТИ (или оставьте None, если набора нет) ===\n",
    "DOCILE_ROOT = os.getenv(\"DOCILE_ROOT\", None) or None      # пример: \"/data/docile\"\n",
    "CORD_ROOT   = os.getenv(\"CORD_ROOT\", None) or None        # пример: \"/data/cord-v2\"\n",
    "SROIE_ROOT  = os.getenv(\"SROIE_ROOT\", None) or None       # пример: \"/data/sroie\"\n",
    "\n",
    "OUT_DIR     = Path(os.getenv(\"SAMPLES_OUT\", \"samples\"))\n",
    "N_DOCILE    = int(os.getenv(\"N_DOCILE\", 12))\n",
    "N_CORD      = int(os.getenv(\"N_CORD\", 12))\n",
    "N_SROIE     = int(os.getenv(\"N_SROIE\", 6))\n",
    "SEED        = int(os.getenv(\"SAMPLES_SEED\", 42))\n",
    "\n",
    "DOCILE_ROOT, CORD_ROOT, SROIE_ROOT, OUT_DIR, N_DOCILE, N_CORD, N_SROIE, SEED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ebc0d9",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Импорты и базовые типы\n",
    "Только стандартная библиотека — чтобы ноутбук легко запускался в разных окружениях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9990d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import hashlib\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\"}\n",
    "PDF_EXTS = {\".pdf\"}\n",
    "LABEL_EXTS = {\".json\", \".txt\"}\n",
    "\n",
    "@dataclass\n",
    "class FoundItem:\n",
    "    src_path: Path\n",
    "    label_path: Optional[Path]\n",
    "    split: str  # 'train' | 'val' | 'test' | 'unknown'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e8292",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Вспомогательные функции\n",
    "- Хэширование (sha256)\n",
    "- Определение сплита по пути\n",
    "- Поиск кандидатов аннотаций рядом с файлом\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96736ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sha256sum(p: Path) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with p.open('rb') as f:\n",
    "        for chunk in iter(lambda: f.read(1024 * 1024), b''):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def guess_split(path: Path) -> str:\n",
    "    s = path.as_posix().lower()\n",
    "    for key in (\"train\", \"training\"):\n",
    "        if f\"/{key}/\" in s or s.endswith(f\"/{key}\"):\n",
    "            return \"train\"\n",
    "    for key in (\"val\", \"valid\", \"validation\"):\n",
    "        if f\"/{key}/\" in s or s.endswith(f\"/{key}\"):\n",
    "            return \"val\"\n",
    "    for key in (\"test\", \"testing\"):\n",
    "        if f\"/{key}/\" in s or s.endswith(f\"/{key}\"):\n",
    "            return \"test\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def numeric_core(stem: str) -> str:\n",
    "    m = re.search(r\"(\\d+)\", stem)\n",
    "    return m.group(1) if m else stem\n",
    "\n",
    "def find_label_candidates(root: Path, target_stem: str) -> List[Path]:\n",
    "    \"\"\"Ищем файлы разметки поблизости по exact stem и по numeric core.\"\"\"\n",
    "    core = numeric_core(target_stem)\n",
    "    candidates: List[Path] = []\n",
    "    up = root\n",
    "    for _ in range(2):  # два уровня вверх (и вниз через rglob)\n",
    "        for ext in LABEL_EXTS:\n",
    "            candidates += list(up.rglob(f\"{target_stem}{ext}\"))\n",
    "            candidates += list(up.rglob(f\"*{core}{ext}\"))\n",
    "        up = up.parent\n",
    "    uniq = []\n",
    "    seen = set()\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            key = c.resolve()\n",
    "            if key not in seen:\n",
    "                uniq.append(c)\n",
    "                seen.add(key)\n",
    "    return uniq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c33713f",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Обнаружение файлов датасетов\n",
    "Эвристики разные для каждого набора.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ece39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def discover_docile(docile_root: Path) -> List[FoundItem]:\n",
    "    items: List[FoundItem] = []\n",
    "    for p in docile_root.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in (IMG_EXTS | PDF_EXTS):\n",
    "            labels = find_label_candidates(p.parent, p.stem)\n",
    "            label = next((x for x in labels if x.suffix.lower() == \".json\"), None)\n",
    "            items.append(FoundItem(src_path=p, label_path=label, split=guess_split(p)))\n",
    "    return items\n",
    "\n",
    "def discover_cord(cord_root: Path) -> List[FoundItem]:\n",
    "    \"\"\"CORD-v2: обычно изображения в {split}/image, метки — в {split}/label.\"\"\"\n",
    "    items: List[FoundItem] = []\n",
    "    for p in cord_root.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in IMG_EXTS:\n",
    "            split = guess_split(p)\n",
    "            label = None\n",
    "            maybe_split_dir = p.parent.parent if p.parent else cord_root\n",
    "            label_dir = maybe_split_dir / \"label\"\n",
    "            if label_dir.exists():\n",
    "                cand = label_dir / f\"{p.stem}.json\"\n",
    "                if cand.exists():\n",
    "                    label = cand\n",
    "            if label is None:\n",
    "                labels = find_label_candidates(p.parent, p.stem)\n",
    "                label = next((x for x in labels if x.suffix.lower() == \".json\"), None)\n",
    "            items.append(FoundItem(src_path=p, label_path=label, split=split))\n",
    "    return items\n",
    "\n",
    "def discover_sroie(sroie_root: Path) -> List[FoundItem]:\n",
    "    items: List[FoundItem] = []\n",
    "    for p in sroie_root.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in IMG_EXTS:\n",
    "            split = guess_split(p)\n",
    "            labels = find_label_candidates(p.parent, p.stem)\n",
    "            label = next((x for x in labels if x.suffix.lower() in (\".txt\", \".json\")), None)\n",
    "            items.append(FoundItem(src_path=p, label_path=label, split=split))\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d34e5fc",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Сэмплирование\n",
    "Простая случайная выборка фиксированного размера.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be077bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pick_samples(items: List[FoundItem], n: int, seed: int) -> List[FoundItem]:\n",
    "    items = list(items)\n",
    "    rnd = random.Random(seed)\n",
    "    rnd.shuffle(items)\n",
    "    return items[:n] if n > 0 else []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2061820a",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Копирование файлов и формирование манифеста\n",
    "Копируем файлы и (если найдены) метки в целевую иерархию, считаем `sha256`, пишем `manifest.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f085fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def copy_item(item: FoundItem, out_dir: Path) -> Tuple[str, Optional[str], str]:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dst = out_dir / item.src_path.name\n",
    "    if not dst.exists():\n",
    "        shutil.copy2(item.src_path, dst)\n",
    "    label_name = None\n",
    "    if item.label_path and item.label_path.exists():\n",
    "        labels_dir = out_dir / \"labels\"\n",
    "        labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        ldst = labels_dir / item.label_path.name\n",
    "        if not ldst.exists():\n",
    "            shutil.copy2(item.label_path, ldst)\n",
    "        label_name = ldst.name\n",
    "    return dst.name, label_name, sha256sum(dst)\n",
    "\n",
    "def write_manifest(rows: List[Dict[str, str]], manifest_path: Path) -> None:\n",
    "    manifest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with manifest_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(\n",
    "            f,\n",
    "            fieldnames=[\n",
    "                \"dataset\",\"doc_type\",\"split\",\"subset_dir\",\"filename\",\"label_filename\",\n",
    "                \"has_gt\",\"sha256\",\"src_path\",\"src_label_path\"]\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b306d8",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Обнаружение доступных документов\n",
    "Запускаем проход по указанным корневым папкам датасетов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e23d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docile_items = discover_docile(Path(DOCILE_ROOT)) if DOCILE_ROOT else []\n",
    "cord_items   = discover_cord(Path(CORD_ROOT))   if CORD_ROOT else []\n",
    "sroie_items  = discover_sroie(Path(SROIE_ROOT)) if SROIE_ROOT else []\n",
    "\n",
    "print(f\"[docile] found: {len(docile_items)}\" if DOCILE_ROOT else \"[docile] skipped\")\n",
    "print(f\"[cord]   found: {len(cord_items)}\" if CORD_ROOT else \"[cord]   skipped\")\n",
    "print(f\"[sroie]  found: {len(sroie_items)}\" if SROIE_ROOT else \"[sroie]  skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3f559",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Сэмплирование и копирование\n",
    "Выбираем нужное количество документов, копируем их в `samples/…`, собираем строки манифеста.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows: List[Dict[str, str]] = []\n",
    "\n",
    "# DocILE (invoices)\n",
    "if DOCILE_ROOT and docile_items:\n",
    "    picked = pick_samples(docile_items, N_DOCILE, SEED)\n",
    "    out_dir = OUT_DIR / \"invoices\" / \"docile\"\n",
    "    for it in picked:\n",
    "        fname, lfname, sha = copy_item(it, out_dir)\n",
    "        rows.append({\n",
    "            \"dataset\": \"docile\",\n",
    "            \"doc_type\": \"invoice\",\n",
    "            \"split\": it.split,\n",
    "            \"subset_dir\": str(out_dir.relative_to(OUT_DIR)),\n",
    "            \"filename\": fname,\n",
    "            \"label_filename\": lfname or \"\",\n",
    "            \"has_gt\": \"1\" if lfname else \"0\",\n",
    "            \"sha256\": sha,\n",
    "            \"src_path\": str(it.src_path.resolve()),\n",
    "            \"src_label_path\": str(it.label_path.resolve()) if it.label_path else \"\",\n",
    "        })\n",
    "    print(f\"[docile] picked: {len(picked)} -> {out_dir}\")\n",
    "\n",
    "# CORD-v2 (receipts)\n",
    "if CORD_ROOT and cord_items:\n",
    "    picked = pick_samples(cord_items, N_CORD, SEED)\n",
    "    out_dir = OUT_DIR / \"receipts\" / \"cord\"\n",
    "    for it in picked:\n",
    "        fname, lfname, sha = copy_item(it, out_dir)\n",
    "        rows.append({\n",
    "            \"dataset\": \"cord-v2\",\n",
    "            \"doc_type\": \"receipt\",\n",
    "            \"split\": it.split,\n",
    "            \"subset_dir\": str(out_dir.relative_to(OUT_DIR)),\n",
    "            \"filename\": fname,\n",
    "            \"label_filename\": lfname or \"\",\n",
    "            \"has_gt\": \"1\" if lfname else \"0\",\n",
    "            \"sha256\": sha,\n",
    "            \"src_path\": str(it.src_path.resolve()),\n",
    "            \"src_label_path\": str(it.label_path.resolve()) if it.label_path else \"\",\n",
    "        })\n",
    "    print(f\"[cord-v2] picked: {len(picked)} -> {out_dir}\")\n",
    "\n",
    "# SROIE (receipts)\n",
    "if SROIE_ROOT and sroie_items:\n",
    "    picked = pick_samples(sroie_items, N_SROIE, SEED)\n",
    "    out_dir = OUT_DIR / \"receipts\" / \"sroie\"\n",
    "    for it in picked:\n",
    "        fname, lfname, sha = copy_item(it, out_dir)\n",
    "        rows.append({\n",
    "            \"dataset\": \"sroie\",\n",
    "            \"doc_type\": \"receipt\",\n",
    "            \"split\": it.split,\n",
    "            \"subset_dir\": str(out_dir.relative_to(OUT_DIR)),\n",
    "            \"filename\": fname,\n",
    "            \"label_filename\": lfname or \"\",\n",
    "            \"has_gt\": \"1\" if lfname else \"0\",\n",
    "            \"sha256\": sha,\n",
    "            \"src_path\": str(it.src_path.resolve()),\n",
    "            \"src_label_path\": str(it.label_path.resolve()) if it.label_path else \"\",\n",
    "        })\n",
    "    print(f\"[sroie] picked: {len(picked)} -> {out_dir}\")\n",
    "\n",
    "print(f\"[total rows] {len(rows)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229feb5",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Запись манифеста и README\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc738c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "manifest_path = OUT_DIR / \"_manifests\" / \"manifest.csv\"\n",
    "write_manifest(rows, manifest_path)\n",
    "\n",
    "readme = OUT_DIR / \"README.samples.md\"\n",
    "readme.write_text(\n",
    "    \"# Week-1 Samples\\n\\n\"\n",
    "    \"- This folder contains reduced samples for R&D (Week 1).\\n\"\n",
    "    \"- Manifest: `_manifests/manifest.csv`.\\n\"\n",
    "    \"- Subsets:\\n\"\n",
    "    \"  - `invoices/docile/` — DocILE samples (invoices)\\n\"\n",
    "    \"  - `receipts/cord/` — CORD-v2 samples (retail receipts)\\n\"\n",
    "    \"  - `receipts/sroie/` — SROIE samples (receipts)\\n\\n\"\n",
    "    \"Notes:\\n\"\n",
    "    \"- Ground-truth labels are copied to `labels/` when found via heuristics.\\n\"\n",
    "    \"- If labels are absent in your local copy, `has_gt=0` will be set.\\n\"\n",
    "    , encoding=\"utf-8\"\n",
    ")\n",
    "manifest_path, readme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091bba5e",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Предпросмотр манифеста (опционально)\n",
    "Если установлен `pandas`, выведем интерактивную таблицу; иначе покажем первые строки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1961b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "manifest_path = OUT_DIR / \"_manifests\" / \"manifest.csv\"\n",
    "if manifest_path.exists():\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        df = pd.read_csv(manifest_path)\n",
    "        # Отображение для пользователя (в веб‑интерфейсе ChatGPT будет табличка)\n",
    "        from caas_jupyter_tools import display_dataframe_to_user\n",
    "        display_dataframe_to_user(\"Week-1 Manifest\", df)\n",
    "    except Exception as e:\n",
    "        print(\"pandas не установлен или отображение недоступно. Покажем первые строки файла:\\n\")\n",
    "        print(\"\\n\".join(manifest_path.read_text(encoding=\"utf-8\").splitlines()[:10]))\n",
    "else:\n",
    "    print(\"Manifest not found:\", manifest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b82de",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Хуки для интеграции с вашим репозиторием\n",
    "Если у вас есть адаптеры в `lib/datasets/adapters/*`, вы можете:\n",
    "- нормализовать метки под вашу Pydantic‑схему (`Invoice/Receipt`),\n",
    "- складывать эталоны в `labels/*.gt.json` для `scripts/eval.py`.\n",
    "\n",
    "Добавьте соответствующий код в отдельную ячейку ниже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Пример (псевдокод):\n",
    "# from lib.datasets.adapters.docile import normalize_docile_label\n",
    "# for lbl in (OUT_DIR / \"invoices\" / \"docile\" / \"labels\").glob(\"*.json\"):\n",
    "#     tgt = lbl.with_suffix(\".gt.json\")\n",
    "#     data = normalize_docile_label(lbl.read_text(encoding=\"utf-8\"))\n",
    "#     tgt.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
